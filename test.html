<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Free GPT-2 Chatbot</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.0.0"></script>
</head>
<body>
  <h1>GPT-2 Chatbot</h1>
  <textarea id="input" rows="4" cols="50" placeholder="Ask something..."></textarea><br>
  <button id="send">Send</button>
  <h2>Response:</h2>
  <pre id="response"></pre>

  <script>
    // Load the GPT-2 model (Check the model URL in your hosting platform)
    async function loadModel() {
      try {
        const model = await tf.loadGraphModel('https://your-hosted-model-url/model.json');  // Replace with the correct model path
        return model;
      } catch (error) {
        console.error('Error loading model:', error);
        return null;
      }
    }

    // Generate text with the GPT-2 model (Simplified for this example)
    async function generateResponse(model, inputText) {
      // GPT-2 requires a sequence of tokens, which needs preprocessing
      // However, for simplicity, we'll simulate the output.
      // Ideally, use a Hugging Face API or a model handler library to handle text generation.
      
      const output = `Simulated response to: ${inputText}`;
      return output;
    }

    document.getElementById('send').addEventListener('click', async () => {
      const userInput = document.getElementById('input').value;
      const responseElement = document.getElementById('response');
      responseElement.textContent = 'Thinking...';

      const model = await loadModel();
      if (model) {
        const output = await generateResponse(model, userInput);
        responseElement.textContent = output;
      } else {
        responseElement.textContent = 'Error loading model. Please try again later.';
      }
    });
  </script>
</body>
</html>